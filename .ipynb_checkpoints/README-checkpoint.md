# Hand Gesture Recognition using Convolutional Neural Networks (CNN)

## ğŸ“Œ Description du projet

Ce projet vise Ã  concevoir et implÃ©menter un systÃ¨me de reconnaissance de gestes de la main en temps rÃ©el Ã  partir dâ€™une webcam, en utilisant des techniques de vision par ordinateur et dâ€™apprentissage profond.  
Le systÃ¨me repose sur un rÃ©seau de neurones convolutif (CNN) entraÃ®nÃ© sur un dataset personnalisÃ© capturÃ© via webcam.

Les gestes reconnus dans ce projet sont des gestes **statiques** :
- fist
- palm
- victory

Le projet couvre lâ€™ensemble de la chaÃ®ne :
- acquisition des donnÃ©es
- prÃ©traitement
- entraÃ®nement du modÃ¨le
- Ã©valuation expÃ©rimentale
- infÃ©rence en temps rÃ©el

---

## ğŸ—‚ï¸ Structure du projet

HandGestureRecognition/
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 04_capture_webcam_data.ipynb
â”‚ â”œâ”€â”€ 05_prepare_webcam_dataset.ipynb
â”‚ â”œâ”€â”€ 06_train_webcam_cnn_clean.ipynb
â”‚ â””â”€â”€ 07_webcam_live_prediction.ipynb
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ webcam_gestures/
â”‚ â””â”€â”€ split_dataset/
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ val/
â”‚ â””â”€â”€ test/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ prepare_dataset.py
â”œâ”€â”€ evaluate_model.py
â”œâ”€â”€ model.h5
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy code

---

## ğŸ§  Description des fichiers principaux

### ğŸ““ Notebooks
- `04_capture_webcam_data.ipynb`  
  Capture des images depuis la webcam et crÃ©ation du dataset brut.
- `05_prepare_webcam_dataset.ipynb`  
  PrÃ©traitement initial des images.
- `06_train_webcam_cnn_clean.ipynb`  
  EntraÃ®nement du modÃ¨le CNN et sauvegarde du modÃ¨le (`model.h5`).
- `07_webcam_live_prediction.ipynb`  
  Tests de prÃ©diction en temps rÃ©el dans Jupyter.

### ğŸ Scripts Python
- `app.py`  
  Script dâ€™infÃ©rence temps rÃ©el utilisant OpenCV et le modÃ¨le entraÃ®nÃ©.
- `prepare_dataset.py`  
  Script de sÃ©paration du dataset en ensembles train / validation / test.
- `evaluate_model.py`  
  Ã‰valuation du modÃ¨le (classification report et matrice de confusion).

---

## âš™ï¸ DÃ©pendances

Les bibliothÃ¨ques nÃ©cessaires au projet sont listÃ©es dans `requirements.txt` :

tensorflow
opencv-python
numpy
matplotlib
scikit-learn
seaborn

clean
Copy code

### Installation des dÃ©pendances
```bash
pip install -r requirements.txt
ğŸ‹ï¸â€â™‚ï¸ EntraÃ®nement du modÃ¨le
Ouvrir le notebook :

stylus
Copy code
06_train_webcam_cnn_clean.ipynb
ExÃ©cuter toutes les cellules jusquâ€™Ã  la sauvegarde du modÃ¨le :

python
Copy code
model.save("model.h5")
Le fichier model.h5 doit se trouver Ã  la racine du projet.

ğŸ“Š Ã‰valuation du modÃ¨le
Lâ€™Ã©valuation est rÃ©alisÃ©e sur lâ€™ensemble de test (15 % des donnÃ©es).

Commande :

bash
Copy code
python evaluate_model.py
RÃ©sultats gÃ©nÃ©rÃ©s :

confusion_matrix.png

Affichage du classification report (accuracy, precision, recall, F1-score)

ğŸ¥ InfÃ©rence en temps rÃ©el (Webcam)
Pour lancer la reconnaissance de gestes en temps rÃ©el :

bash
Copy code
python app.py
Fonctionnement :

La webcam sâ€™ouvre automatiquement

Le geste dÃ©tectÃ© est affichÃ© sur la vidÃ©o

Appuyer sur q pour quitter

ğŸ§ª ParamÃ¨tres principaux du modÃ¨le
Taille des images : 64 Ã— 64

Mode couleur : niveaux de gris

Optimiseur : Adam

Fonction de perte : Categorical Cross-Entropy

Batch size : 32

Nombre dâ€™Ã©poques : 20

âš ï¸ Limitations
SensibilitÃ© Ã  lâ€™Ã©clairage et Ã  lâ€™arriÃ¨re-plan

Dataset de taille limitÃ©e

Reconnaissance uniquement de gestes statiques

ğŸš€ Perspectives
Ajout de data augmentation

Reconnaissance de gestes dynamiques (CNN + LSTM)

Utilisation de MediaPipe pour lâ€™extraction de landmarks

DÃ©ploiement sous forme dâ€™application desktop ou web

ğŸ‘¤ Auteur
Projet rÃ©alisÃ© par :
MACHHOUR ISMAIL
MALLOUK MOHAMED TAHA

EncadrÃ© par :
Mme Salma CHRIT

AnnÃ©e universitaire : 2025 â€“ 2026

ğŸ“œ Licence
Ce projet est rÃ©alisÃ© dans un cadre acadÃ©mique.
Toute utilisation commerciale nÃ©cessite une autorisation prÃ©alable.